import os
import base64
import streamlit as st
from openai import AzureOpenAI
import fitz  # PyMuPDF
from dotenv import load_dotenv

load_dotenv()

AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_API_VERSION = "2025-01-01-preview"

# â€” Azure OpenAI ã®è¨­å®š â€”
DEPLOYMENT = "gpt-4o-mini-audio-preview"

client = AzureOpenAI(
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
)

SYSTEM_PROMPT1 = """
ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç¿»è¨³è€…ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸæ—¥æœ¬èªï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯éŸ³å£°ï¼‰ã‚’ã€è‹±èªå‚è€ƒè³‡æ–™ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚„ç”¨èªã‚’åæ˜ ã—ã¦å¿ å®Ÿã«è‹±è¨³ã—ã€éŸ³å£°åˆæˆã—ã¦ãã ã•ã„ã€‚
"""
SYSTEM_PROMPT2 = """
ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€ä¸€å­—ä¸€å¥å¤‰ãˆãšã«å¿ å®Ÿã«ãã®ã¾ã¾å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å‡ºåŠ›ã—ãŸå¾Œã¯ç›´ã¡ã«å‡ºåŠ›ã‚’æ‰“ã¡åˆ‡ã£ã¦ãã ã•ã„ã€‚
"""

def extract_text_from_pdf(file) -> str:
    """
    fitz (PyMuPDF) ã‚’ä½¿ã£ã¦ PDF ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    """
    doc = fitz.open(stream=file.read(), filetype="pdf")
    text = []
    for page in doc:
        txt = page.get_text()
        if txt:
            text.append(txt)
    return "\n".join(text)

def translate_and_speak(system_prompt,
                        text=None,
                        audio_bytes=None,
                        audio_ext="wav",
                        reference=None):
    # messages ã®çµ„ç«‹
    messages = [{"role": "system", "content": system_prompt}]
    if reference:
        messages.append({
            "role": "system",
            "content": f"## å‚è€ƒè³‡æ–™\n{reference}"
        })

    if text:
        messages.append({"role": "user", "content": text})
    else:
        b64 = base64.b64encode(audio_bytes).decode("utf-8")
        messages.append({
            "role": "user",
            "content": [
                {"type": "input_audio",
                 "input_audio": {"data": b64, "format": audio_ext}}
            ]
        })

    # Azure OpenAI å‘¼ã³å‡ºã—
    resp = client.chat.completions.create(
        model=DEPLOYMENT,
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
        messages=messages,
    )
    transcript = resp.choices[0].message.audio.transcript
    audio_b64 = resp.choices[0].message.audio.data
    audio_out = base64.b64decode(audio_b64)
    return transcript, audio_out

# --- Streamlit UI ---
st.title("ğŸˆ‚ï¸ æ—¥æœ¬èªâ†’è‹±èª ç¿»è¨³ï¼‹éŸ³å£°åˆæˆï¼ˆå‚è€ƒè³‡æ–™å¯¾å¿œç‰ˆï¼‰")

# å‚è€ƒè³‡æ–™ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_ref = st.file_uploader(
    "å‚è€ƒè³‡æ–™ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆPDFã¾ãŸã¯TXTï¼‰", type=["pdf", "txt"]
)
reference_text = ""
if uploaded_ref is not None:
    ext = os.path.splitext(uploaded_ref.name)[1].lower()
    if ext == ".pdf":
        reference_text = extract_text_from_pdf(uploaded_ref)
    else:
        reference_text = uploaded_ref.read().decode("utf-8")

input_mode = st.radio("å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["ãƒ†ã‚­ã‚¹ãƒˆ", "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«"])
system_prompt = st.radio("å‡ºåŠ›ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["ç¿»è¨³", "èª­ã¿ä¸Šã’"])

user_text = None
user_audio = None
audio_ext = "wav"

if input_mode == "ãƒ†ã‚­ã‚¹ãƒˆ":
    user_text = st.text_area("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›", height=150)
else:
    uploaded = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["wav", "mp3", "m4a"])
    if uploaded is not None:
        user_audio = uploaded.read()
        audio_ext = os.path.splitext(uploaded.name)[1].lstrip(".")

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ç¿»è¨³ï¼†åˆæˆå®Ÿè¡Œ"):
    if (input_mode == "ãƒ†ã‚­ã‚¹ãƒˆ" and not user_text) or (input_mode == "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«" and not user_audio):
        st.error("å…¥åŠ›ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
    else:
        if system_prompt == "ç¿»è¨³":
            prompt = SYSTEM_PROMPT1
        else:
            prompt = SYSTEM_PROMPT2

        with st.spinner("å‡¦ç†ä¸­â€¦"):
            text_out, audio_out = translate_and_speak(
                system_prompt=prompt,
                text=user_text,
                audio_bytes=user_audio,
                audio_ext=audio_ext,
                reference=reference_text
            )
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open("output.txt", "w", encoding="utf-8") as f_txt:
                f_txt.write(text_out)
            with open("output.wav", "wb") as f_wav:
                f_wav.write(audio_out)
            st.session_state["generated"] = True

# çµæœè¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
if st.session_state.get("generated"):
    st.success("å®Œäº†ï¼")
    st.subheader("â–¶ï¸ ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›")
    with open("output.txt", "r", encoding="utf-8") as f_txt:
        st.write(f_txt.read())
    st.subheader("ğŸ”Š éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    with open("output.wav", "rb") as f_wav:
        st.audio(f_wav.read(), format="audio/wav")
    with open("output.wav", "rb") as f_wav:
        st.download_button(
            "ğŸ”½ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            f_wav,
            file_name="output.wav",
            mime="audio/wav",
            key="audio_dl"
        )
    with open("output.txt", "rb") as f_txt:
        st.download_button(
            "ğŸ”½ ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            f_txt,
            file_name="output.txt",
            mime="text/plain",
            key="text_dl"
        )
