import os
import base64
import streamlit as st
from openai import AzureOpenAI
import fitz  # PyMuPDF

# â€” Azure OpenAI ã®è¨­å®š â€”
AZURE_OPENAI_ENDPOINT = os.environ.get("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.environ.get("AZURE_OPENAI_API_KEY")
API_VERSION = "2025-01-01-preview"
DEPLOYMENT = "gpt-4o-mini-audio-preview"

client = AzureOpenAI(
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_key=AZURE_OPENAI_API_KEY,
    api_version=API_VERSION,
)

SYSTEM_PROMPT = """
ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç¿»è¨³è€…ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸæ—¥æœ¬èªï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯éŸ³å£°ï¼‰ã‚’ã€ä»¥ä¸‹ã®è‹±èªå‚è€ƒè³‡æ–™ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚„ç”¨èªã‚’åæ˜ ã—ã¦å¿ å®Ÿã«è‹±è¨³ã—ã€éŸ³å£°åˆæˆã—ã¦ãã ã•ã„ã€‚
"""

def extract_text_from_pdf(file) -> str:
    """
    fitz (PyMuPDF) ã‚’ä½¿ã£ã¦ PDF ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    """
    doc = fitz.open(stream=file.read(), filetype="pdf")
    text = []
    for page in doc:
        txt = page.get_text()
        if txt:
            text.append(txt)
    return "\n".join(text)

def translate_and_speak(text=None, audio_bytes=None, audio_ext="wav", reference=None):
    # messages ã®çµ„ç«‹
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    if reference:
        messages.append({
            "role": "system", 
            "content": f"## å‚è€ƒè³‡æ–™ï¼ˆè‹±èªï¼‰\n{reference}"})

    if text:
        messages.append({"role": "user", "content": text})
    else:
        b64 = base64.b64encode(audio_bytes).decode("utf-8")
        messages.append({
            "role": "user",
            "content": [
                {"type": "input_audio",
                 "input_audio": {"data": b64, "format": audio_ext}}
            ]
        })

    # Azure OpenAI å‘¼ã³å‡ºã—
    resp = client.chat.completions.create(
        model=DEPLOYMENT,
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
        messages=messages,
    )
    transcript = resp.choices[0].message.audio.transcript
    audio_b64 = resp.choices[0].message.audio.data
    audio_out = base64.b64decode(audio_b64)
    return transcript, audio_out

# --- Streamlit UI ---
st.title("ğŸˆ‚ï¸ æ—¥æœ¬èªâ†’è‹±èª ç¿»è¨³ï¼‹éŸ³å£°åˆæˆï¼ˆå‚è€ƒè³‡æ–™å¯¾å¿œç‰ˆï¼‰")

# å‚è€ƒè³‡æ–™ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_ref = st.file_uploader(
    "è‹±èªå‚è€ƒè³‡æ–™ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆPDFã¾ãŸã¯TXTï¼‰", type=["pdf", "txt"]
)
reference_text = ""
if uploaded_ref is not None:
    ext = os.path.splitext(uploaded_ref.name)[1].lower()
    if ext == ".pdf":
        reference_text = extract_text_from_pdf(uploaded_ref)
    else:
        reference_text = uploaded_ref.read().decode("utf-8")

input_mode = st.radio("å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["ãƒ†ã‚­ã‚¹ãƒˆ", "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«"])

user_text = None
user_audio = None
audio_ext = "wav"

if input_mode == "ãƒ†ã‚­ã‚¹ãƒˆ":
    user_text = st.text_area("æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›", height=150)
else:
    uploaded = st.file_uploader("æ—¥æœ¬èªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["wav", "mp3", "m4a"])
    if uploaded is not None:
        user_audio = uploaded.read()
        audio_ext = os.path.splitext(uploaded.name)[1].lstrip(".")

if st.button("ç¿»è¨³ï¼†åˆæˆå®Ÿè¡Œ"):
    if (input_mode == "ãƒ†ã‚­ã‚¹ãƒˆ" and not user_text) or (input_mode == "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«" and not user_audio):
        st.error("å…¥åŠ›ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("å‡¦ç†ä¸­â€¦"):
            text_out, audio_out = translate_and_speak(
                text=user_text,
                audio_bytes=user_audio,
                audio_ext=audio_ext,
                reference=reference_text
            )
        st.success("å®Œäº†ï¼")
        st.subheader("â–¶ï¸ ç¿»è¨³çµæœï¼ˆè‹±èªï¼‰")
        st.write(text_out)
        st.subheader("ğŸ”Š éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.audio(audio_out, format="audio/wav")
        st.download_button("ğŸ”½ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", audio_out, file_name="output.wav", mime="audio/wav")
        st.download_button("ğŸ”½ ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", text_out, file_name="output.txt", mime="text/plain")
